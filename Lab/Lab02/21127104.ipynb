{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "858de05e",
   "metadata": {},
   "source": [
    "# Lab 2: Numpy\n",
    "In this Numpy exercise, the general requirement is not to use loops; I will specify where it is allowed\n",
    "\n",
    "(Last update: 12/11/2023)\n",
    "\n",
    "Name: Đoàn Ngọc Mai \n",
    "Sdudent ID: 21127104\n",
    "\n",
    "---\n",
    "\n",
    "## 0. Instructions for doing and submitting assignment\n",
    "\n",
    "**How to do your assignment**\n",
    "\n",
    "You will do your assignment directly on this notebook file. First, you fill your name and student code at the beginning of the file. In this file, you will write your code when you see the following lines of code:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "For optional coding parts, there will be:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "\n",
    "For markdown cell, there will be:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "Of course, you have to remove the `raise NotImplementedError()` statement when you finish.\n",
    "\n",
    "For coding parts, there are often cells below to help you check your answers. You will pass the test if there are no errors when you run the test cells. In some cases, the tests are insufficient. That means if you do not pass the test, your answer is definitely wrong somewhere, but if you pass the test, your answer may still be incorrect.\n",
    "\n",
    "While doing the assignment, you should print out the output and create more cells for testing. But you have to remove all of them (comment your print-out codes, delete the cell created by you) when you submit your code. <font color=red>Do not remove or edit my cells</font> (except for the aforementioned cells).\n",
    "\n",
    "Keep your code clean and clear by using meaningful variable names and comments, not write too-long coding lines.\n",
    "Press `Ctrl + S` right after editing.\n",
    "\n",
    "Keep it real: The reason why you are here is to <font color=green>study, really study</font>. I highly recommend that you discuss your idea with your friends and <font color=green>write your own code based on your own knowledge</font>. <font color=red>Copy means zero.</font>\n",
    "\n",
    "**How to submit your assignment**\n",
    "\n",
    "When grading your assignment, I will choose `Kernel` - `Restart & Run All` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n",
    "\n",
    "After that, rename the notebook as `<Student ID>.ipynb`. For example, if your student code is 1234567, then your notebook is `1234567.ipynb`.\n",
    "\n",
    "Finally, submit your notebook file on Moodle. <font color=red>Please strictly follow the submission rules.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bce3092",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeaa165",
   "metadata": {},
   "source": [
    "## 1. Programming environment\n",
    "\n",
    "- You will re-use the Linux environment setup in Lab 0 - WarmUp. Don't forget to start your coding environment (`conda activate min_ds-env`) before doing your assignment.\n",
    "- Use Jupyter notebook or Jupyter lab, <font color=red>not Google Colab</font> (I can not grade you well on Google Colab) to edit your `*.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "097d1336",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\ADMIN\\\\anaconda3\\\\envs\\\\min_ds-env\\\\python.exe'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf9ded",
   "metadata": {},
   "source": [
    "- If there are no problems, the file to run python will be the file of the \"min_ds-env\" code environment.\n",
    "\n",
    "- In this article, you are not using the Pandas library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b4612",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ce8fea",
   "metadata": {},
   "source": [
    "## 2. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6630d75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b5f965",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116d0050",
   "metadata": {},
   "source": [
    "## 3. Data collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e283245",
   "metadata": {},
   "source": [
    "Numpy is not a great library for handling operations like data reading and writing, but it's an excellent library for computational tasks. Therefore, in this article, we'll simply use the pre-collected dataset that I've attached in the folder of this lab. This dataset actually contains multiple files and is relatively large, but it has been curated to include relevant information for this lab. You can learn more about this dataset [here](https://www.kaggle.com/datasets/hernan4444/anime-recommendation-database-2020).\n",
    "\n",
    "Here is a specific description of the dataset:\n",
    ">The full dataset have the list of all animes register by the user with the respective score, watching status and numbers of episodes watched. This dataset contains 109 Million row, 17.562 different animes and 325.772 different users. The file have the following columns:\\\n",
    "1 - user_id: non identifiable randomly generated user id.\\\n",
    "2 - anime_id: MyAnemlist ID of the anime. (e.g. 1).\\\n",
    "3 - score: score between 1 to 10 given by the user. 0 if the user didn't assign a score. (e.g. 10)\\\n",
    "4 - watching_status: state ID from this anime in the anime list of this user. (e.g. 2)\\\n",
    "5 - watched_episodes: numbers of episodes watched by the user. (e.g. 24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c46dd35",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0554a",
   "metadata": {},
   "source": [
    "## 4. Data exploring & Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86a5001",
   "metadata": {},
   "source": [
    "### How many rows and columns does the data have?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b82236",
   "metadata": {},
   "source": [
    "Of course, the first thing you need to do is read the data file into the Numpy array and name it `user_ratings` (use function `np.genfromtxt`). You may encounter some minor problems with this task, it seems that all the data in the Numpy array is not what we want. This happens because the function `np.genfromtxt` has a default data type of `float`, you need to find a way to convert it to `uint64`. You should put the dataset file in the same directory as this notebook file to simplify when passing the file name to the function. Finally, you need to calculate the number of rows and columns for this dataset, these two values are stored in two variables `nrows` and `ncols` respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "0ab3481b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "user_ratings = np.genfromtxt('anime.txt', dtype=np.uint64, delimiter='\\t')\n",
    "nrows, ncols = user_ratings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "665c47a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 866,  138,    0,    6,    0],\n",
       "       [ 858,  696,    0,    6,    0],\n",
       "       [ 617,  147,    0,    6,    0],\n",
       "       [ 481, 1951,    8,    2,    3],\n",
       "       [ 890,  690,    6,    2,   26]], dtype=uint64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST\n",
    "assert user_ratings.dtype == np.uint64\n",
    "assert user_ratings.ndim == 2\n",
    "assert nrows == 66338\n",
    "assert ncols == 5\n",
    "user_ratings[:5] # Look at the first 5 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35b930b",
   "metadata": {},
   "source": [
    "### Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e554ab90",
   "metadata": {},
   "source": [
    "#### The meaning of each row\n",
    "\n",
    "Each row in the data set shows some information about a user's score for a anime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bacd8d",
   "metadata": {},
   "source": [
    "#### Does the data have duplicate rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb71b6",
   "metadata": {},
   "source": [
    "You will test this case and save the results to the `have_duplicated_rows` variable. This variable will have the value True if the data has duplicate lines and will have the value False otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "badd6cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "unique_rows, counts = np.unique(user_ratings, axis=0, return_counts=True)\n",
    "have_duplicated_rows = len(unique_rows) < len(user_ratings)\n",
    "\n",
    "# print(have_duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4f1bffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert have_duplicated_rows == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c19f96d",
   "metadata": {},
   "source": [
    "Great, so there are no duplicate rows. Next we will explore the columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d9f80",
   "metadata": {},
   "source": [
    "### Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625b73c3",
   "metadata": {},
   "source": [
    "#### The meaning of each column\n",
    "- The first column indicates the user's ID (user_ID)\n",
    "- The second column indicates the ID of the anime movie (anime_ID)\n",
    "- The third column shows the score at which the user rated the movie (ratings)\n",
    "- The fourth column indicates watching status (watching_status)\n",
    "- The fifth column indicates the episode watched (watched_episodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832ed6ab",
   "metadata": {},
   "source": [
    "#### What data type does each column currently have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f877453d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint64')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_ratings.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4db741",
   "metadata": {},
   "source": [
    "At first glance, it seems that all columns are numeric. But in my opinion, the two columns `user_id` and `anime_id` should be classified into categorical groups. The reason for this is because both `user_id` and `anime_id` are simply identifiers and do not necessarily have an arithmetic relationship between the columns. Of course, this is just an objective perspective and not true for all cases, but to make it easier to work, in this lab we will agree with the above thought."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813f3930",
   "metadata": {},
   "source": [
    "#### For each column with numeric datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34421ec3",
   "metadata": {},
   "source": [
    "First, we need to see how many missing values the numeric columns have. This mission is quite 'difficult' ^^ so I will do it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "b1bc561a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(user_ratings[:, 2:]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c090a7b8",
   "metadata": {},
   "source": [
    "Great, so all numeric columns don't have any missing values.\n",
    "\n",
    "Now, your job is to calculate the min, Q1(25%), median, Q3(75%) and max of these numeric columns. You will need to use the `np.percentile` function to do this. Then, the all values of each column are saved respectively into 3 Numpy arrays namely `rating_percentile`, `status_percentile`, `episodes_percentile`. Also, make sure that these Numpy arrays all have the `uint64` data type so you don't get into trouble with the TEST cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "8a4cfdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "numeric_columns = user_ratings[:, 2:]\n",
    "\n",
    "rating_percentile = np.percentile(numeric_columns[:, 0], [0, 25, 50, 75, 100], interpolation='nearest').astype(np.uint64)\n",
    "status_percentile = np.percentile(numeric_columns[:, 1], [0, 25, 50, 75, 100], interpolation='nearest').astype(np.uint64)\n",
    "episodes_percentile = np.percentile(numeric_columns[:, 2], [0, 25, 50, 75, 100], interpolation='nearest').astype(np.uint64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "8ccf440b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert np.array_equal(rating_percentile, np.array([0, 0, 5, 8, 10]))\n",
    "assert np.array_equal(status_percentile, np.array([1, 2, 2, 6, 6]))\n",
    "assert np.array_equal(episodes_percentile, np.array([0, 0, 1, 24, 36600]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542f3da",
   "metadata": {},
   "source": [
    "#### For each column with categorical datatype, how are the values distributed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a708fc2",
   "metadata": {},
   "source": [
    "Just like with numeric columns, we need to see if two categorical columns have missing values? (This is difficult so let me do it for you :v )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "41aeae4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isnan(user_ratings[:, :2]), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7746f1",
   "metadata": {},
   "source": [
    "Your task is to, for each column, calculate a list of 5 numbers: the number of distinct values, the value that appears least with its corresponding count (total of 2 numbers), and the value that appears most with its corresponding count (total of 2 numbers). You should store the 2 lists calculated for 2 columns in two variables, namely `user_profile` and `anime_profile`. If multiple users rate the least number of movies, we will agree to choose the user with the smallest id. And vice versa, if many users rate the most movies, we will choose the user with the largest id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "464c0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "user_ids, user_counts = np.unique(user_ratings[:, 0], return_counts=True)\n",
    "min_user_count_idx = np.argmin(user_counts)\n",
    "max_user_count_idx = np.argmax(user_counts)\n",
    "\n",
    "user_profile = [\n",
    "    len(user_ids),  \n",
    "    user_ids[min_user_count_idx], \n",
    "    user_counts[min_user_count_idx],  \n",
    "    user_ids[max_user_count_idx],  \n",
    "    user_counts[max_user_count_idx]  \n",
    "]\n",
    "\n",
    "anime_ids, anime_counts = np.unique(user_ratings[:, 1], return_counts=True)\n",
    "min_anime_count_idx = np.argmin(anime_counts)\n",
    "max_anime_count_idx = np.argmax(anime_counts)\n",
    "\n",
    "anime_profile = [\n",
    "    len(anime_ids),  \n",
    "    anime_ids[min_anime_count_idx],  \n",
    "    anime_counts[min_anime_count_idx],  \n",
    "    anime_ids[max_anime_count_idx],  \n",
    "    anime_counts[max_anime_count_idx]  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "742cbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert user_profile == [898, # Có chừng này user\n",
    "                        31,  # Đây là user rate ít movie nhất\n",
    "                        1,  # và đó là chừng này movie\n",
    "                        890, # Đây là user rate nhiều movie nhất\n",
    "                        1138] # và đó là chừng này movie\n",
    "assert anime_profile == [1801,#Có chừng này movie\n",
    "                         115, #Đây là movie được ít user rate nhất\n",
    "                         1,   #và đó là chừng này user\n",
    "                         1535,  #Đây là movie được nhiều user rate nhất\n",
    "                         701] #và đó là chừng này user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02cefe4",
   "metadata": {},
   "source": [
    "Incidentally, we need to check the maximum and minimum values of the two columns `user_id` and `anime_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "be8889db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User id  - min & max: 0 & 1000\n",
      "Anime id - min & max: 1 & 2000\n"
     ]
    }
   ],
   "source": [
    "print('User id  - min & max:', \n",
    "      user_ratings[:, 0].min(), '&', user_ratings[:, 0].max()) \n",
    "print('Anime id - min & max:', \n",
    "      user_ratings[:, 1].min(), '&', user_ratings[:, 1].max()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c3fbca",
   "metadata": {},
   "source": [
    "\"It can be observed that for `user_id`, there is nothing unusual, but for `anime_id`, the first anime is numbered from 1 instead of 0 like `user_id`. Although this is not a significant issue, for convenience in the subsequent implementation, we need to normalize the `anime_id` column.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6cdf8f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_ratings[:, 1] = user_ratings[:, 1] - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0cff7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22b5c3a",
   "metadata": {},
   "source": [
    "## 5. Question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00e8647",
   "metadata": {},
   "source": [
    "The previous section was just to warm you up before diving into the main content of this lab. Now, we have a bit better understanding of the dataset. We will attempt to pose meaningful questions and find answers using the data.\n",
    "\n",
    "One interesting question to ask is: *For each different user, is it possible to recommend animes that the user has never watched before?*\n",
    "\n",
    "Finding an answer to this question can be beneficial for both users and movie streaming service providers:\n",
    "- Users: Users may want to watch a movie, but with so many options available, they may not know which one to choose. It would be convenient for users if the system could suggest a list of movies that they are likely to enjoy.\n",
    "- Movie Streaming Service Providers: If the system makes good recommendations, it's more likely that users will watch and enjoy the movies. This, in turn, means users will continue to pay for the service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a76fc7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfd9472",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece65a3d",
   "metadata": {},
   "source": [
    "First, we need to decide which information to use in building the anime recommendation system. Obviously, the columns `user_id`, `anime_id`, and `rating` are essential to perform this task. As for the two columns `watching_status` and `watched_episodes`, these columns can still have value in practice when building a recommendation model. However, for simplicity, we will temporarily set aside these two columns here.\n",
    "\n",
    "Based on 3 columns, you need to create a 2D NumPy matrix named `ratings_mat`. In this matrix, the number of rows represents the number of users, while the number of columns represents the number of anime. So, `ratings_mat[i, j]` will represent the rating that `user_i` has given to `anime_j`. \"For anime series that the user has not rated, the value will be 'NaN'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3974d25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# # raise NotImplementedError()\n",
    "num_users = np.max(user_ratings[:, 0]).astype(int)\n",
    "num_anime = np.max(user_ratings[:, 1]).astype(int)\n",
    "\n",
    "# Create a matrix of NaNs for the ratings, adding 1 to account for zero-based indexing\n",
    "ratings_mat = np.full((num_users + 1, num_anime + 1), np.nan)\n",
    "\n",
    "user_ids = user_ratings[:, 0]\n",
    "anime_ids = user_ratings[:, 1]\n",
    "scores = user_ratings[:, 2]\n",
    "\n",
    "scores = np.where(scores == 0, np.nan, scores)\n",
    "\n",
    "ratings_mat[user_ids, anime_ids] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6822489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ratings_mat.shape == (1001, 2000)\n",
    "missing_ratios = np.mean(np.isnan(ratings_mat))\n",
    "assert missing_ratios.round(3) == 0.982"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e34a223",
   "metadata": {},
   "source": [
    "### Analyze data to answer the question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283e379f",
   "metadata": {},
   "source": [
    "It would be much simpler if we used algorithms supported by other libraries. However, the main goal of this lab is to help you practice using the Numpy library. Therefore, you will have the opportunity to build a simple anime recommendation system from scratch using the provided data, utilizing only Numpy library. Please remember that Numpy doesn't favor loops, so you are only allowed to use loops where I explicitly permit.\n",
    "\n",
    "In my opinion, there are two fundamental tasks in a anime recommendation system:\n",
    "\n",
    "- First, you need to predict the ratings for animes that a user hasn't reviewed or watched yet.\n",
    "- Second, you need to provide recommendations to users based on the top-rated animes that have been predicted.\n",
    "\n",
    "It seems that the second task will become much simpler if we can accomplish the first task. One of the simplest ways to tackle task 1 is by computing the similarity between users and using this similarity to make predictions. However, there are some considerations to keep in mind. It's not feasible to compute similarity between all users at once, as it might lead to memory issues (even if you have enough memory, my computer is quite limited in that regard :<). One way to address this issue is to process a group of users at a time, referred to as `a batch`. To keep it simple, let's stick with a `batch_size = 32`, which I believe is a reasonable value. You should try to make your code work with a single batch first and then extend it to process all batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b62778",
   "metadata": {},
   "source": [
    "\"First, you will try with a batch corresponding to users with indices from `start` to `end`.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "701e8fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "start = 0\n",
    "end = batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbdc6fd",
   "metadata": {},
   "source": [
    "Step 1: Calculate the `similarities` array to show the similarity between each user in the current batch with all users in the entire dataset. This array will have a size of `batch_size` x `n_users` (`n_users` is the total number of users in the dataset), where `similarities[i, j]` indicates the similarity between `user_i` and `user_j`. In the case where two users have no common rated movies (when running, you may see a warning 'RuntimeWarning: Mean of empty slice'), you set the similarity to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1d751cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13924\\3763824203.py:5: RuntimeWarning: Mean of empty slice\n",
      "  a = np.nanmean(a, axis=2)  # Ignore nan\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "r0 = ratings_mat[start:end, :]\n",
    "a = np.abs(ratings_mat - r0[:, np.newaxis, :])\n",
    "a = np.nanmean(a, axis=2)  # Ignore nan\n",
    "\n",
    "similarities = 1 / (a + 0.001)  # Add 0.001 to avoid dividing by 0\n",
    "\n",
    "similarities = np.nan_to_num(similarities, nan=0)\n",
    "# similarities[:3, :3].round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1720a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert similarities.shape == (32, 1001)\n",
    "assert np.array_equal(similarities[:3, :3].round(1), \n",
    "                      np.array([[1.0e+03, 6.0e-01, 2.0e+00],\n",
    "                                [6.0e-01, 1.0e+03, 1.5e+00],\n",
    "                                [2.0e+00, 1.5e+00, 1.0e+03]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f582808",
   "metadata": {},
   "source": [
    "Step 2: calculate the `weights` matrix. The array `weights` will have the size `batch_size` x `n_users` x `n_movies` (where `n_movies` is the total number of movies). About how to calculate `weights`, you can refer to file `example.ipynb`.\n",
    "\n",
    "When running, you will see the warning \"RuntimeWarning: invalid value encountered in true_divide\"; This is because the users who rate a movie under consideration all have a similarity of 0 with a user under review, resulting in normalization to 0/0 and the result is difficult. This case means there is not enough information to predict the score and in this article, you should leave it as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "766f776f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13924\\1399081430.py:4: RuntimeWarning: invalid value encountered in divide\n",
      "  weights = weights/weights.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "weights = ~np.isnan(ratings_mat)*similarities.reshape(batch_size, -1, 1)\n",
    "weights = weights/weights.sum(axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0180000d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert weights.shape == (32, 1001, 2000)\n",
    "assert np.sum(np.isnan(weights)) == 16462446"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5249bfb0",
   "metadata": {},
   "source": [
    "Step 3: For each user in the batch under consideration, calculate the score (for all movies) by multiplying the score of all users with the corresponding weight in the `weight` array; then write each user's scores down to one line in the `filled_ratings` array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "59f6ba0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_ratings = np.empty_like(ratings_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5c8a2d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "filled_ratings[start:end] = np.nansum(ratings_mat * weights, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c84b5f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_batch = filled_ratings[start:end]\n",
    "filled_nanvals = filled_batch[np.isnan(ratings_mat[start:end])]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([8.6, 0. , 0. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([0., 0., 0.]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f558f3",
   "metadata": {},
   "source": [
    "Great ! So your code has run on a batch, now it's time for you to use the `for` loop to cycle through all the batches in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8ea23646",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13924\\3132856473.py:10: RuntimeWarning: Mean of empty slice\n",
      "  similarities = 1 / (np.nanmean(absolute_diff, axis=-1) + 0.001)\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_13924\\3132856473.py:16: RuntimeWarning: invalid value encountered in divide\n",
      "  weight = weight / weight.sum(axis=1, keepdims=True)\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "\n",
    "num_batches = len(ratings_mat) // batch_size + int(len(ratings_mat) % batch_size > 0)\n",
    "batches = np.array_split(ratings_mat, num_batches)\n",
    "filled_ratings = np.empty((0, 2000), dtype=float)\n",
    "\n",
    "for batch in batches:\n",
    "    absolute_diff = np.abs(ratings_mat[:, None] - batch)\n",
    "    similarities = 1 / (np.nanmean(absolute_diff, axis=-1) + 0.001)\n",
    "    \n",
    "    similarities = np.transpose(similarities)\n",
    "    similarities[np.isnan(similarities)] = 0\n",
    "    \n",
    "    weight = ~np.isnan(ratings_mat) * similarities.reshape(len(batch), -1, 1)\n",
    "    weight = weight / weight.sum(axis=1, keepdims=True)\n",
    "    \n",
    "    weighted_sum = np.nansum(ratings_mat * weight, axis=1)\n",
    "    \n",
    "    filled_ratings = np.append(filled_ratings, weighted_sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "063f85c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "filled_nanvals = filled_ratings[np.isnan(ratings_mat)]\n",
    "assert np.array_equal(filled_nanvals[:3].round(1),\n",
    "                      np.array([8.6, 0. , 0. ]))\n",
    "assert np.array_equal(filled_nanvals[-3:].round(1),\n",
    "                      np.array([5.7, 5. , 6.6]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
